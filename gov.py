# -*- coding: utf-8 -*-
"""gov.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k8AANALhP_a9jbjf87vXce6VRTxujWG1
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
os.chdir('/content/drive/My Drive/Colab Notebooks/gov')

import pandas as pd
from nltk.tokenize import word_tokenize
import re

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.layers import Dropout
import re
from nltk.corpus import stopwords
from nltk import word_tokenize

cpgram = pd.read_csv("/content/drive/My Drive/Colab Notebooks/gov/cpgrams.csv", encoding='latin1')
movement_cpgram = pd.read_csv("/content/drive/My Drive/Colab Notebooks/gov/cpgrams_movement.csv")

cpgram_grp = cpgram.groupby('registration_no')
cpgram_grp_df = pd.DataFrame(cpgram_grp)

reg_no_cpg = cpgram['registration_no'].unique()
reg_no_mov_cpg = movement_cpgram['registration_no'].unique()
len(reg_no_cpg)

complaint = pd.DataFrame(cpgram_grp.first())
len(complaint.index)
complaints = complaint.subject_content
complaints = complaints.reset_index()

def text_clean_one():
    for i in range(0, len(complaints.subject_content), 1):
        # complaints['subject_content'].iloc[i] = re.sub("RT @[\w_]+: ", "",complaints['subject_content'].iloc[i])  # Removes RT @<username>:
        # complaints['subject_content'].iloc[i] = re.sub("<.*?>", "", complaints['subject_content'].iloc[i])  # Removes HTML tags.
        complaints['subject_content'].iloc[i] = re.sub(r'[^\x00-\x7F]+', ' ', str(complaints['subject_content'].iloc[i]))  # only ascii
        complaints['subject_content'].iloc[i] = re.sub(' +', ' ', str(complaints['subject_content'].iloc[i]))  # replacing spaces to single space
        complaints['subject_content'].iloc[i] = complaints['subject_content'].iloc[i].lower()  # converting to lower case
        # complaints['subject_content'].iloc[i] = re.sub("[^\w\s]", "", complaints['subject_content'].iloc[i])  # Removes punctuations
        complaints['subject_content'].iloc[i] = re.sub('[^0-9a-zA-Z ]+', "", str(complaints['subject_content'].iloc[i]))  # Keeps only alphanumeric
    return complaints


clean_complaints = text_clean_one()

len(clean_complaints)

for j in range(0, len(clean_complaints), 1):
    if len(clean_complaints.subject_content[j].split())< 5:
        clean_complaints = clean_complaints.drop([j])

clean_complaints1=pd.read_csv("clean_complaints.csv")

clean_complaints1

reg_no = clean_complaints1.registration_no

reg_no_cp = pd.DataFrame(reg_no)

reg_no_cp.registration_no = reg_no_cp.registration_no.str.replace(' ', '')

reg_no_cp['registration_no'].iloc[1]

reg_no_cp_list=list(reg_no_cp['registration_no'])

len(reg_no_cp)

len(reg_no_cp)

check = 'TAKEN UP WITH SUBORDINATE ORGANISATION'
org_name1 = []
reg_number = []
inc=0
for i in range(len(common_reg_no)):
    count = len(common_reg_no) - i
    a = common_reg_no[i]
    print(count)
    flag = 0
    for j in range(inc,len(movement_cpgram)):
        b = movement_cpgram['registration_no'].iloc[j]
        to_check = movement_cpgram['action_name'].iloc[j]
        if a == b and check == to_check and flag == 0:
            reg_number.append(a)
            org_name1.append(movement_cpgram['org_name'].iloc[j])
            flag = 1
            inc=j

clean_complaints.subject_conte

complaints_t=[]
for i in range(len(org_name)):
  for j in range(len(reg_no_cp_list)):
    if reg_no[i]==reg_no_cp_list[j]:
      complaints_t.append(clean_complaints.subject_content[j])

reg_no[0]==clean_complaints.registration_no[0]

with open('org_name.txt', 'w') as filehandle:
    for listitem in org_name1:
        filehandle.write('%s\n' % listitem)

with open('reg_no.txt', 'w') as filehandle:
    for listitem in reg_number:
        filehandle.write('%s\n' % listitem)

clean_complaints1

f=open('org_name.txt','r')
org_name=f.read().splitlines()

len(org_name)

f=open('reg_no.txt','r')
reg_no=f.read().splitlines()

f=open('complaints.txt','r')
complaints_a=f.read().splitlines()

len(reg_no)



df = pd.DataFrame(org_name)

complaints_a=[]
inc=0
for i in range(len(reg_no)):
  count = len(reg_no) - i
  print(count)
  a=reg_no[i]
  for j in range(inc,len(clean_complaints1)):
    b=reg_no_cp['registration_no'].iloc[j]
    if a==b:
      complaints_a.append(clean_complaints1['subject_content'].iloc[j])
      inc=j

len(complaints_a)



with open('complaints.txt', 'w') as filehandle:
    for listitem in complaints_a:
        filehandle.write('%s\n' % listitem)

data_gov = pd.DataFrame(
    {'registration_no': reg_no,
     'complaints': complaints_a,
     'org_name': org_name
    })

data_gov

data_gov.head(5)

# The maximum number of words to be used. (most frequent)
MAX_NB_WORDS = 33200
# Max number of words in each complaint.
MAX_SEQUENCE_LENGTH = 200
# This is fixed.
EMBEDDING_DIM = 100

tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(data_gov['complaints'].values)
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))

tokenizer

import pickle

# saving

with open('tokenizer2.pickle', 'wb') as handle:

    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

# # loading

# with open('tokenizer.pickle', 'rb') as handle:

#     tokenizer = pickle.load(handle)

with open('word_index2.pkl', 'wb') as f:
        pickle.dump(word_index, f)

# with open('word_index.pkl', 'rb') as handle:
#   word_index = pickle.load(handle)

word_index

X = tokenizer.texts_to_sequences(data_gov['complaints'].values)
X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH, padding='post')
print('Shape of data tensor:', X.shape)

Y = pd.get_dummies(data_gov['org_name']).values
print('Shape of label tensor:', Y.shape)

Y

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.30, random_state = 41)
print(X_train.shape,Y_train.shape)
print(X_test.shape,Y_test.shape)

X[1]

X.shape[1]

model = Sequential()
model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(LSTM(300, dropout=0.01, recurrent_dropout=0.01))
model.add(Dense(23, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])
print(model.summary())

epochs = 10
batch_size = 32

history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)

accr = model.evaluate(X_test,Y_test)
print('Test set\n  Loss: {:0.3f}\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))

accr = model.evaluate(X_test,Y_test)
print('Test set\n  Loss: {:0.3f}\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))

model.save('model_gov4.h5')

from keras.models import load_model
model2 = load_model('model_gov4.h5')

import numpy as np

new_complaint = ['Respected SirThe return of total income for A.Y. ****-** ****-** and ****-** were filed by us on **/**/**** **/**/**** and **/**/**** vide acknowledgment No. ****** ***** and ***** claiming refunds of Rs. Rs.*****/- Rs.*****/- and Rs.****/- respectively. Sir we have approached the income tax department many times personally and through our authorized representative for issue of the aforesaid refunds however no response is received from income tax department till date. We have filed grievance on CPGRAMS vide Reference No. CBODT/E/****/***** that was erroneously disposed off without issuing the refund by assuming that the grievance was filed in name of M/s. R C Transport however the same was filed for the firm M/s. S A Transport. It is requested that necessary directions may please be given to the concerned authorities for our application for issue of refund and oblige.']
seq = tokenizer.texts_to_sequences(new_complaint)
padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')
pred = model2.predict(padded)

# labels = ['Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Mortgage', 'Credit card or prepaid card', 'Student loan', 'Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Payday loan, title loan, or personal loan', 'Vehicle loan or lease', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Prepaid card']
labels=['Ministry of Labour and Employment','Department of Health & Family Welfare','Department of Higher Education', 'Department of Defence','Government of NCT of Delhi','Central Board of Direct Taxes (Income Tax)','Ministry of Railways ( Railway Board)','Department of Financial Services (Banking Division)','Department of Posts', 'Department of Telecommunications','Department of Defence Finance','Central Board of Indirect Taxes and Customs','Ministry of Housing and Urban Affairs','Ministry of Home Affairs','Ministry of Petroleum and Natural Gas','Ministry of External Affairs','Department of Personnel and Training','Government of Madhya Pradesh', 'Government of Tamil Nadu','Government of Gujarat', 'Government of Puducherry','Government of Haryana','Department of Financial Services (Insurance Division)']
print(pred, labels[np.argmax(pred)])

# labels=['Ministry of Labour and Employment','Department of Health & Family Welfare','Department of Higher Education', 'Department of Defence','Government of NCT of Delhi','Central Board of Direct Taxes (Income Tax)','Ministry of Railways ( Railway Board)','Department of Financial Services (Banking Division)','Department of Posts', 'Department of Telecommunications','Department of Defence Finance','Central Board of Indirect Taxes and Customs','Ministry of Housing and Urban Affairs','Ministry of Home Affairs','Ministry of Petroleum and Natural Gas','Ministry of External Affairs','Department of Personnel and Training','Government of Madhya Pradesh', 'Government of Tamil Nadu','Government of Gujarat', 'Government of Puducherry','Government of Haryana','Department of Financial Services (Insurance Division)']

len(labels)

data_gov['org_name'].unique()

new_complaint = ['RESPECTED SIR/MADAMI HAVE FILED FOR REFUND OF MY TAX UNDER APPEAL EFFECT ON **-**-**** THEN ON **-**-**** AND THEREAFTER ON **-**-**** BUT TILL DATE I HAVE NOT RECEIVED ANY CONFIRMATION ABOUT MY REFUND. I AM OLD AND IN NEED OF THIS REFUND TO LOOK AFTER MYSELF. PLEASE DO THE NEEDFUL AT THE EARLIEST. THE REFUND BELONGS TO ASSESSMENT YEARS ****-** *****-** AND ****-**. MY PAN IS AMEPR****A. COPY OF ASSESSMENT ORDER HAS BEEN ATTACHED FOR YOUR REFERENCE.']
seq = tokenizer.texts_to_sequences(new_complaint)
padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH,padding='post')
pred = model2.predict(padded)

# labels = ['Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Mortgage', 'Credit card or prepaid card', 'Student loan', 'Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Payday loan, title loan, or personal loan', 'Vehicle loan or lease', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Prepaid card']
labels=['Ministry of Labour and Employment','Department of Health & Family Welfare','Department of Higher Education', 'Department of Defence','Government of NCT of Delhi','Central Board of Direct Taxes (Income Tax)','Ministry of Railways ( Railway Board)','Department of Financial Services (Banking Division)','Department of Posts', 'Department of Telecommunications','Department of Defence Finance','Central Board of Indirect Taxes and Customs','Ministry of Housing and Urban Affairs','Ministry of Home Affairs','Ministry of Petroleum and Natural Gas','Ministry of External Affairs','Department of Personnel and Training','Government of Madhya Pradesh', 'Government of Tamil Nadu','Government of Gujarat', 'Government of Puducherry','Government of Haryana','Department of Financial Services (Insurance Division)']
print(pred, labels[np.argmax(pred)])



new_complaint = ['I had submitted original documents of house ( H. NO. *** Sector - ** Panchkula ) with Central Excise Commissioner ate  Chandigarh -II for obtaining Home loan from the department  . On */*/** I requested for release of the same.  enclosing there with the No Dues Certificate issued by the DDO Customs Commissioner ate  Ludhiana  my last place of posting from where I had taken VRS . So for I have received only one reply (through mail ) on */*/** from the AO (ET-II) GST Sub- Commissioer ate Mohali  forwarding thereunder the copy of their letter written to A C Customs for verification . It was mentioned that my request will be considered after getting reply . Now period of almost one and half year has elapsed but no communication for release of  documents been communicated to me  despite my repeated requests. Please take up the issue with the concerned . Regards . Subhash Batra  Retired Assistant Commissioner']
seq = tokenizer.texts_to_sequences(new_complaint)
padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)
pred = model2.predict(padded)

# labels = ['Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Mortgage', 'Credit card or prepaid card', 'Student loan', 'Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Payday loan, title loan, or personal loan', 'Vehicle loan or lease', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Prepaid card']
labels=['Ministry of Labour and Employment','Department of Health & Family Welfare','Department of Higher Education', 'Department of Defence','Government of NCT of Delhi','Central Board of Direct Taxes (Income Tax)','Ministry of Railways ( Railway Board)','Department of Financial Services (Banking Division)','Department of Posts', 'Department of Telecommunications','Department of Defence Finance','Central Board of Indirect Taxes and Customs','Ministry of Housing and Urban Affairs','Ministry of Home Affairs','Ministry of Petroleum and Natural Gas','Ministry of External Affairs','Department of Personnel and Training','Government of Madhya Pradesh', 'Government of Tamil Nadu','Government of Gujarat', 'Government of Puducherry','Government of Haryana','Department of Financial Services (Insurance Division)']
print(pred, labels[np.argmax(pred)])

data_gov.groupby('org_name').count()